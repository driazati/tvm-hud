[
  {
    "sha": "b0c63b587de714afbc1ecd24bdfc964b61d69e8f",
    "headline": "Remove attributes of relax.print, assert and unique (#443)",
    "body": "* Remove Attr of assert, print and unique\n\n* use relax.null_value\n\n* Fix comments\n\n* Fix comments. Remove null_value\n\n* Fix 421",
    "author": "yongwww",
    "date": "2023-02-23T12:33:25Z",
    "jobs": [],
    "updated_at": 1724721018.213366
  },
  {
    "sha": "9b34d043cb54377acc5a50427ae5c54e00e426ba",
    "headline": "comply with the recent changes (#447)",
    "body": "",
    "author": "sunggg",
    "date": "2023-02-19T12:38:53Z",
    "jobs": []
  },
  {
    "sha": "d69e247fab2e1be9fb7e050cd8faec91716c6e5c",
    "headline": "[Op] Add an operator for comparing shape values (#438)",
    "body": "",
    "author": "slyubomirsky",
    "date": "2023-02-18T23:47:52Z",
    "jobs": []
  },
  {
    "sha": "44bbc2cde5321c231c2fe81063e08f0c8b075a64",
    "headline": "[Bugfix] Correct reshape detector logic (#445)",
    "body": "Currently, reshape detector does not compare the size of `src_buffer` and `dst_buffer` and this leads to the false positive as reported in https://github.com/tlc-pack/relax/issues/444. \r\n\r\nThis PR fixes this problem.",
    "author": "sunggg",
    "date": "2023-02-17T23:43:25Z",
    "jobs": []
  },
  {
    "sha": "89322564a00d4628ab33a1a644947ccdf80518b0",
    "headline": "[CUTLASS] Update cutlass generator to add fp32 SIMT kernels (#451)",
    "body": "* Sync cutlass generator and add fp32 SIMT kernels\r\n\r\n* Update library.py\r\n\r\n* lint",
    "author": "vinx13",
    "date": "2023-02-17T02:38:13Z",
    "jobs": []
  },
  {
    "sha": "c9492f55bed3576530b21483c82af6df0c328f55",
    "headline": "[CUTLASS] Finish host codegen clean up (#448)",
    "body": "",
    "author": "masahi",
    "date": "2023-02-17T01:48:04Z",
    "jobs": []
  },
  {
    "sha": "d08f87e5ba3bc7796f81265e804855db3c3a8876",
    "headline": "[BYOC] Fix FuseOpsByPattern and RunCodegen for calling the same exter\u2026",
    "body": "\u2026n multiple times (#441)",
    "author": "masahi",
    "date": "2023-02-16T18:23:42Z",
    "jobs": []
  },
  {
    "sha": "5e6c6abe5cf45c35412976902e9ab69ac543c854",
    "headline": "[CUTLASS] Move matmul host codegen to python (#442)",
    "body": "* Move matmul host codegen to python\r\n\r\n* add doc\r\n\r\n* fix for i64 shape\r\n\r\n* lint\r\n\r\n* more lint\r\n\r\n* std::vector<string> -> Array<String> for func_args\r\n\r\n* move batch matmul codegen to python",
    "author": "masahi",
    "date": "2023-02-16T03:58:54Z",
    "jobs": []
  },
  {
    "sha": "df3c5af64fd7d57bba752fde17dde346736348a5",
    "headline": "Lower shape_of in compilation (#439)",
    "body": "",
    "author": "slyubomirsky",
    "date": "2023-02-15T05:07:27Z",
    "jobs": []
  },
  {
    "sha": "0926c751fcd1fae49943b585c33323d12d3c82d9",
    "headline": "[Tweak] Use StructInfo instead of a type for `assert_op`'s StructInfo\u2026",
    "body": "\u2026-checking rule (#440)\n\n* Use StructInfo instead of type for assert's FInferStructInfo\r\n\r\n* Fix line length",
    "author": "slyubomirsky",
    "date": "2023-02-15T04:37:55Z",
    "jobs": []
  },
  {
    "sha": "84cd0652d08b4a2c2fe151413824c33b42670602",
    "headline": "[BYOC] Add matmul to relax CUTLASS BYOC (#418)",
    "body": "* Add matmul to relax cutlass BYOC flow\r\n\r\n* Rename dense to matmul\r\n\r\n* Fix accuracy issue with explicit dtype\r\n\r\n* Fix format\r\n\r\n* Fix inaccurary issue on gelu\r\n\r\n* Reset random seed\r\n\r\n* Use IRBuilder to create IRModule\r\n\r\n* Cleanup tests",
    "author": "yelite",
    "date": "2023-02-15T00:54:58Z",
    "jobs": []
  },
  {
    "sha": "ce5c7f4117e4fcc33894a1449f751f32f8e1460e",
    "headline": "[Op] Remove MatchCast requirement for manipulation ops (#436)",
    "body": "Prior to this PR, the structure info inference of some manipulation\r\noperators rejects unknown ndim or unknown shape for safety reason.\r\nAs many people are pointing out, this requirement increases the\r\noverhead of our frontend importers, in the way of forcing the\r\nimporters to use MatchCast, which turns out to be ineffective and\r\ntroublesome.\r\n\r\nTherefore, this PR removes such requirements, turning into the\r\nbehavior of optimistically trust the input that they have the desired\r\nndim or shape when those properties are unknown.\r\n\r\nNevertheless, this PR leaves TODO items at such places, which serve\r\nas reminders for us to support corresponding runtime ndim or shape\r\ncheck in the future.",
    "author": "MasterJH5574",
    "date": "2023-02-14T01:39:25Z",
    "jobs": []
  },
  {
    "sha": "69a970083b21e6ddfa539fe396673d339f43aaac",
    "headline": "[TVMScript] Use explicit `R.shape` in TVMScript (#435)",
    "body": "As we've introduced `arg_sinfo` in CallNode, implicit shape constructor\r\nis not widely used in TVMScript. This PR removes the implicit shape since\r\nit may cause confusion between shape and tuple.",
    "author": "Hzfengsy",
    "date": "2023-02-13T19:50:35Z",
    "jobs": []
  },
  {
    "sha": "530292534b9aa0ebda9892746f0bae2e5fd4b152",
    "headline": "[UX][TVMScript] Overload `__neg__` for relax expr (#434)",
    "body": "This PR overloads `__neg__` given that `relax.negative` is now supported and adds corresponding tests.",
    "author": "SiriusNEO",
    "date": "2023-02-13T19:49:37Z",
    "jobs": []
  },
  {
    "sha": "c9fb54bee6663cefce6ddb1f913d334dc7ee8c2b",
    "headline": "[CUTLASS] Fix test accuracy (#433)",
    "body": "",
    "author": "masahi",
    "date": "2023-02-13T16:42:22Z",
    "jobs": []
  },
  {
    "sha": "ab102542b5807c687833c68979d87f1910e06fb1",
    "headline": "[Frontend] Adding missing pieces of Torch `from_fx` (#431)",
    "body": "",
    "author": "MasterJH5574",
    "date": "2023-02-12T07:56:26Z",
    "jobs": []
  },
  {
    "sha": "02f1ca72d0356fbc52ea11e81b03a0f1e3848a5b",
    "headline": "[Fix] FuseOps/FuseTIR skip ExternFunc for call_dps_packed (#429)",
    "body": "This PR fixes FuseOps and FuseTIR, which did not take\r\n\"call_dps_packed\" into consideration and thus directly downcasted\r\nthe first argument of \"call_tir\" to GlobalVar.\r\n\r\nTherefore, this PR fixes this issue by skipping callee that is not a\r\nGlobalVar.",
    "author": "MasterJH5574",
    "date": "2023-02-12T00:26:02Z",
    "jobs": []
  },
  {
    "sha": "7482f6d2813741b70cae5ea3ef27a8f56b081cd6",
    "headline": "[Pipeline][Torch] Introducing pipeline and Torch Dynamo backend (#428)",
    "body": "This PR contains two parts, with the first part being a pipeline\r\nprototype, and the second part being the a backend of Torch Dynamo\r\nusing Relax.\r\n\r\n* The pipeline prototype contains the collection of pre-defined\r\npipelines that optimizes and lower IRModule before passing to minimum\r\nbuild.\r\n\r\n* The Dynamo backend brings the mechanism to build PyTorch model\r\nusing Relax compilation pipeline.\r\n\r\nCo-authored-by: Tianqi Chen <tianqi.tchen@gmail.com>\r\nCo-authored-by: Bohan Hou <32121147+spectrometerHBH@users.noreply.github.com>",
    "author": "MasterJH5574",
    "date": "2023-02-11T23:06:10Z",
    "jobs": []
  },
  {
    "sha": "7b7b16959fd93e288128a0a0347309d29a216ea0",
    "headline": "[Analysis] Memory usage estimation (#412)",
    "body": "This PR brings an analysis function which estimates the memory usage\nof Relax functions, used for demonstrating the effect of memory planning.\n\nThe estimation will return the total memory size needed to be allocated\nbefore and after memory planning, as well as the number of tensors / memory\nblocks to be allocated before and after memory planning.\n\nNote:\n* The estimation is static -- it does not consider control flows (such\nas \u201cif\u201d and cross-function calls). It simply accumulates the size of\nevery alloc_tensor and alloc_storage.\n* We regards \u201c`relax.memory.alloc_tensor/storage`\u201d as the results\nproduced by memory planning.",
    "author": "MasterJH5574",
    "date": "2023-02-11T13:21:12Z",
    "jobs": []
  },
  {
    "sha": "5431c98d6bd258719d0430f6573d267a5aca74a2",
    "headline": "[Pass] Operator Legalization (#425)",
    "body": "This PR is the operator legalization pass, which transforms high-level\r\noperator calls to `call_tir`s of corresponding low-level TIR PrimFuncs.\r\n\r\n* The legalization pass provides customizability, which enables people\r\nto pass in a customized legalization map to override the default\r\nlegalization method.\r\n\r\n* The legalization supports symbolic shape. (At this moment only\r\npooling does not support symbolic shape, as TOPI pooling does not\r\nsupport. This needs to be fixed in followup PRs.)\r\n\r\n* For fast development, as a first step we put the pass on Python side,\r\nwhich is fine enough at this moment. Eventually, we will move the pass\r\nto C++ side, with the legalization functions registered per op in\r\noperator registry.\r\n\r\n---\r\n\r\nCo-authored-by: Chaofan Lin <siriusneo@sjtu.edu.cn>\r\nCo-authored-by: Yixin Dong <ubospica@gmail.com>\r\nCo-authored-by: Siyuan Feng <Hzfengsy@sjtu.edu.cn>",
    "author": "MasterJH5574",
    "date": "2023-02-11T02:46:54Z",
    "jobs": []
  },
  {
    "sha": "c4c5c8735e2fcf6dbbdd30af8436548c87d3e720",
    "headline": "[Fix][Transform] FuseOps handling multiple src functions (#427)",
    "body": "This PR fixes FuseOps so that it can now handle muitlple Relax\r\nfunctions instead of only doing fusion in function \"main.\"\r\n\r\nSpecifically, this PR\r\n* fixes FuseOps as described above.\r\n* adds a unit test to FuseOps to ensure it works for multiple src\r\nfunctions.\r\n* adds a unit test to FuseTIR to ensure it works for multiple src\r\nfunctions.\r\n* removes the internal `IsLeaf` funciton in FuseOps as it duplicates\r\nwith the existing util.",
    "author": "MasterJH5574",
    "date": "2023-02-11T02:43:15Z",
    "jobs": []
  },
  {
    "sha": "a6f133ceae99a887062b9d14bda3124645981a40",
    "headline": "[BYOC] Minor clean up in cutlass codegen (#426)",
    "body": "* simplify cutlass codegen\r\n\r\n* check pattern name\r\n\r\n* abort if the pattern is not recognized",
    "author": "masahi",
    "date": "2023-02-11T01:27:51Z",
    "jobs": []
  },
  {
    "sha": "923a2144e9c792b0dd696812426692e4a1193ac9",
    "headline": "[Relax][frontend] torch fx importer (#419)",
    "body": "Implements the Relax importer from PyTorch, using torch FX.\r\n\r\n\r\n\r\nCo-authored-by: Ruihang Lai <ruihangl@cs.cmu.edu>",
    "author": "spectrometerHBH",
    "date": "2023-02-10T23:21:22Z",
    "jobs": []
  },
  {
    "sha": "62889e4baf840515f73647c5deb554007dd1adb7",
    "headline": "[RUNTIME] Use Array to back Tuple (#424)",
    "body": "",
    "author": "tqchen",
    "date": "2023-02-10T20:30:36Z",
    "jobs": []
  },
  {
    "sha": "ab266c99e0e9e44c00a2464d5897df0356a44d60",
    "headline": "Remove Attr for alloc_storage and alloc_tensor (#420)",
    "body": "",
    "author": "yongwww",
    "date": "2023-02-10T20:29:00Z",
    "jobs": []
  },
  {
    "sha": "5695e8bd17804cb965d0eb2663458c36664239be",
    "headline": "[VM] Add per-op profiling support (#422)",
    "body": "",
    "author": "masahi",
    "date": "2023-02-10T15:29:13Z",
    "jobs": []
  },
  {
    "sha": "7053d2018635e78dd95782d8fc3a4da231d783db",
    "headline": "[Tweak] Note that `PrimValue`, `DataTypeImm`, and `StringImm` are lea\u2026",
    "body": "\u2026f nodes (#423)\n\n* Consider PrimValue, DataTypeImm, and StringImm to be leaf nodes\n\n* LeafExprNode actually handled the case already",
    "author": "slyubomirsky",
    "date": "2023-02-10T04:18:19Z",
    "jobs": []
  },
  {
    "sha": "aa8a7303397cb17a4b3f4e11234995de43925734",
    "headline": "[Pass] BindingBlock-level static memory planning (#407)",
    "body": "This PR introduces the static memory planning pass on binding block level.\r\n\r\n* The detailed pass document is in the [implementation file](https://github.com/MasterJH5574/relax/blob/relax-dev/2023-02-04-memory-planning/src/relax/transform/static_plan_block_memory.cc).\r\n\r\n* The static memory planning supports nested tuples.\r\n\r\n* The static memory planning supports reuse memory of the input of\r\nreshape ops.\r\n\r\n* This PR brings the lowering of memory ops (`memory.alloc/kill_storage`,\r\n`memory.alloc/kill_tensor`) in the VMBuiltinLower pass as well, to support\r\nmemory planning.\r\n\r\n* The PR provides unit tests for the memory planning to my best knowledge.",
    "author": "MasterJH5574",
    "date": "2023-02-10T03:08:39Z",
    "jobs": []
  },
  {
    "sha": "b16fcf09d8fe6bf53e9eb19b315fc96616bb8bc5",
    "headline": "Disallow inline prim_func in relax IR (#414)",
    "body": "* Disallow inline prim_func in relax IR\r\n\r\n* fix comments",
    "author": "yongwww",
    "date": "2023-02-09T05:32:02Z",
    "jobs": []
  },
  {
    "sha": "3cbe967463ca945cf29caebcf8987df4cac2936d",
    "headline": "Fix after rebase",
    "body": "",
    "author": "junrushao",
    "date": "2023-02-09T00:05:41Z",
    "jobs": []
  },
  {
    "sha": "c8b31236466243d2106e4b3243582e9d7c1ba654",
    "headline": "[Transform] RewriteDataflowReshape to op and VMBuiltinLower handling \u2026",
    "body": "\u2026(#415)\n\n* [Transform] RewriteDataflowReshape to op and VMBuiltinLower handling\r\n\r\nPriior to this PR, the pass transforms calls of reshape\r\nPrimFunc in dataflow blocks to direct calls of runtime packed func\r\n\u201cvm.builtin.reshape.\u201d The consequence of this behavior is that the\r\nmemory planning pass has to check the reshape op by string comparison\r\nof `ExternFunc.global_symbol`, which is not ideal.\r\n\r\nTherefore, this PR changes the RewriteDataflowReshape\u2019s behavior,\r\ntransforming calls of reshape PrimFunc to our high-level reshape op\r\n\u201crelax.reshape,\u201d and let the VMBuiltinLower pass to lowers the op to\r\ncalls of \u201cvm.builtin.reshape.\u201d",
    "author": "MasterJH5574",
    "date": "2023-02-09T01:26:39Z",
    "jobs": []
  },
  {
    "sha": "187ae0729a099de8549abd27823aaf772cc9c51f",
    "headline": "[TVMScript] Relax Printer (#416)",
    "body": "This PR migrates the relax printer to use the latest printer infrastructure",
    "author": "junrushao",
    "date": "2023-02-08T13:57:16Z",
    "jobs": []
  },
  {
    "sha": "418513885e1a4fa18213e9dc7abd51edf7a68264",
    "headline": "[BYOC] Fix problems in MergeCompositeFunctions (#411)",
    "body": "* Fix problems in merge_composite_functions\r\n\r\n* Update doc\r\n\r\n* Unify private methods and update code",
    "author": "yelite",
    "date": "2023-02-08T02:57:15Z",
    "jobs": []
  },
  {
    "sha": "48b7d5e647b74ffcbda128265a29c0779e877dca",
    "headline": "[Util] NestedMsg: MapNestedMsg (#410)",
    "body": "This PR brings a new util function (`MapNestedMsg`) for NestedMsg:\r\n\r\n* `MapNestedMsg` recurses into an input NestedMsg and maps the leaves\r\naccording to the provided mapping function.\r\n\r\nOne corresponding unit test is provided.",
    "author": "MasterJH5574",
    "date": "2023-02-07T23:58:58Z",
    "jobs": []
  },
  {
    "sha": "7a8423b84ac2b4f2d8640ae87f0c760711fb365e",
    "headline": "[BYOC] Update TensorRT backend for the new BYOC flow and offloading w\u2026",
    "body": "\u2026ith constants (#400)\n\n* Update TensorRT backend for the new BYOC flow and offloading with constant\n\n* update cutlass codegen for the new signature\n\n* add comment\n\n* fix pattern partitioning for residual block\n\n* update cutlass rev and enable disabled test",
    "author": "masahi",
    "date": "2023-02-07T21:41:43Z",
    "jobs": []
  },
  {
    "sha": "deabb9b42559bb404932ca32b1a957ff223bfe43",
    "headline": "[Op][Layout] Add layout_transform operator in Relax. (#403)",
    "body": "Adds layout_transform operator in Relax as part of Relax layout planning.\r\n\r\nlayout_transform takes an input tensor x and an attribute index_map of tir::IndexMap type. It also has an optional pad_value attribute. It transforms x as per the index_map attribute and returns the transformed tensor.\r\n\r\nThis operator for now allows layout transformations that introduce implicit padding. For example, transforming a tensor of shape (10,) using the lambda i: (i//4, i%4). The output shape will be (3, 4) with two elements padded. The optional pad_value is used to pad if specified, otherwise the compiler is free to choose any value to pad.",
    "author": "psrivas2",
    "date": "2023-02-07T18:51:23Z",
    "jobs": []
  },
  {
    "sha": "0c87483eb95ce9a0bdc2dff4a7e4d2bc1c99dd39",
    "headline": "[OP] Add Linear Op Interface at Python Side (#409)",
    "body": "As discussed before, we won't introduce a new Linear Op at IR level.\r\nHowever, this PR adds a user interface at the python side, which is composed of transpose, matmul and a bias add.",
    "author": "Hzfengsy",
    "date": "2023-02-07T18:23:31Z",
    "jobs": []
  },
  {
    "sha": "5c3ec46a7469159390cf2246d92da038ed5ec0bd",
    "headline": "[Op] Add `relax.clip` Op (#408)",
    "body": "",
    "author": "Hzfengsy",
    "date": "2023-02-07T17:55:41Z",
    "jobs": []
  },
  {
    "sha": "2f09775bd57747d88ca2736ec2e3abf69be03a46",
    "headline": "Replace CopyWithNewParams with CopyWithNewVars (#406)",
    "body": "This PR adds a CopyWithNewVars function to replace CopyWithNewParams. CopyWithNewVars will copy all variables defined in a function, rather than just copy function parameters like what CopyWithNewParams does.\r\n\r\nWhen the copy of a function needs to be added to the same IRModule of original function, it's important that the copy doesn't use the same variable as the original function does. Otherwise it's not possible to assert structural equal between the result and an IRModule created through TVMScript, which is a common pattern used in tests.",
    "author": "yelite",
    "date": "2023-02-06T19:20:55Z",
    "jobs": []
  },
  {
    "sha": "616c855abbd7c8787de0da1c369fcbbcd363e970",
    "headline": "[Fix][Arith] Analyzer simplification starts with canonical (#13875) (\u2026",
    "body": "\u2026#404)\n\nThis PR updates the order of arithmetic analyzer simplification, by\nadding a stage of canonical simplification at the very beginning so\nthat every simplification always starts with a canonical round. This\nis because the rewrite simplification may destroy some PrimExpr property\nthat the canonical simplification can make use of. Therefore, adding\nthe canonical one in the front can maximize the use of canonical\nsimplification.",
    "author": "MasterJH5574",
    "date": "2023-02-03T18:59:31Z",
    "jobs": []
  },
  {
    "sha": "945f89dea8e809f9380868f40445808012d90232",
    "headline": "Add back the missing optional header (#401)",
    "body": "",
    "author": "yelite",
    "date": "2023-02-03T00:17:44Z",
    "jobs": []
  },
  {
    "sha": "ff689ca56c2252ebbbf73669825303defc4f5f4d",
    "headline": "[BYOC] Add CUTLASS backend (#380)",
    "body": "* Add CUTLASS backend\n\n* fix\n\n* Wrap and annotate in FuseOpsByPattern optionally\n\n* fix\n\n* black\n\n* add test for FuseOpsByPattern change\n\n* black\n\n* ignore 3rd party in pylint\n\n* fix test\n\n* another unused var warning\n\n* Update include/tvm/relax/transform.h\n\nCo-authored-by: Wuwei Lin <vincentl13x@gmail.com>\n\n* fix for v3\n\n* fix for int8 test in relay byoc\n\n* more fix for cutlass update\n\n* fix residual block fusion offload\n\n* fix test\n\n---------\n\nCo-authored-by: Wuwei Lin <vincentl13x@gmail.com>",
    "author": "masahi",
    "date": "2023-02-02T21:20:45Z",
    "jobs": []
  },
  {
    "sha": "28c2d25683dd4f59a117f7defd53dcc4d9cde85e",
    "headline": "[BYOC] Fix MergeCompositeFunctions when some callees are not a compos\u2026",
    "body": "\u2026ite function (#385)",
    "author": "masahi",
    "date": "2023-02-02T21:05:42Z",
    "jobs": []
  },
  {
    "sha": "036ae9a543877a4ff69d00b54aaa3f1b3d1cb7e3",
    "headline": "Move PyVisitor/Mutator into cc file (#398)",
    "body": "",
    "author": "LeshengJin",
    "date": "2023-02-02T20:57:09Z",
    "jobs": []
  },
  {
    "sha": "8c6c3e94c8eaf4bf28e364a9c50a0249578765c4",
    "headline": "[Fix][Pass] TIR op pattern kind analysis with int var in signature (#\u2026",
    "body": "\u2026399)\n\nThis PR fixes a bug in TIR pattern kind analyzer.\r\n\r\nPreviously the analyzer requires the input TIR function signature\r\nnot to have any symbolic var other than Buffer var. This behavior\r\nwill throw exception whenever the input TIR function signature contains\r\ninteger var or other var, while the expected behavior is to ignore\r\nthese vars instead of throwing error. This PR fixes this issue.",
    "author": "MasterJH5574",
    "date": "2023-02-02T18:07:15Z",
    "jobs": []
  },
  {
    "sha": "fcc25b1a18daa6980b183bae6152da470c2584ca",
    "headline": "[Pass] Rewrite dataflow reshape (#393)",
    "body": "This PR introduces the dataflow reshape rewrite pass, which transform all\r\ndataflow TIR reshape bindings inside a Relax function into a call of\r\nruntime packed function `relax.vm.builtin.reshape`. Here \u201cdataflow TIR\r\nreshape bindings\u201d means\r\n1. the binding value is a `call_tir` of any PrimFunc that is essentially\r\ndoing a reshape operation,\r\n2. the binding var is a DataflowVar, or in other words, the binding is\r\ninside a DataflowBlock and the binding var is not a block output var.\r\n\r\nThe `relax.vm.builtin.reshape` packed function creates a view of the input\r\nNDArray with the target shape, instead of doing data copy.\r\n\r\nIn order to fulfill this pass, this PR contains the following parts.\r\n1. An analysis function that detects the reshape pattern of PrimFuncs.\r\n2. The dataflow reshape rewrite pass itself.\r\n3. The implementation of `relax.vm.builtin.reshape` as a PackedFunc.\r\n\r\nThis PR contains unit tests for each part.",
    "author": "MasterJH5574",
    "date": "2023-02-02T18:06:48Z",
    "jobs": []
  },
  {
    "sha": "35d7382508a34704d8f574d551ede43e28b68f83",
    "headline": "Allow keeping bound constants in OperatorFusor (#397)",
    "body": "",
    "author": "masahi",
    "date": "2023-02-02T07:09:26Z",
    "jobs": []
  },
  {
    "sha": "4fd316e4d575911c00ea0ab9cd8b37b9815ee365",
    "headline": "[Debugging] Support PrimValue, StringImm, and DataTypeImm in the AST \u2026",
    "body": "\u2026printer (#396)",
    "author": "slyubomirsky",
    "date": "2023-02-01T06:10:26Z",
    "jobs": []
  },
  {
    "sha": "faa0ee60319e5e42f3ff52a2e744042dc43840d5",
    "headline": "[Fix] Type comparison in auto arg converter (#394)",
    "body": "Previously when running all relax unit tests on my machine using\r\n`pytest test_*`, one auto argument converter tests always fail.\r\n(And when I only run that single test, it passes very well.)\r\n\r\nAfter inspection, I noted that in the failed test, though `anno`\r\nis printed as `typing.Optional[tvm.ir.expr.RelayExpr]`, the comparison\r\nbelow `anno is Optional[Expr]` still results false.\r\nhttps://github.com/tlc-pack/relax/blob/2e5e47962238be7385486241203d1a8146f38a0e/python/tvm/relax/utils.py#L252-L253\r\n\r\nI tweaked the comparison to `in` and all tests seem to pass very\r\nsuccessfully. I guess the issue might relate to some address issue (?)\r\nbut I\u2019m not 100% sure about this.",
    "author": "MasterJH5574",
    "date": "2023-02-01T04:11:21Z",
    "jobs": []
  },
  {
    "sha": "791e1422ac319a774303b9a0965264ebeedbc834",
    "headline": "[Fix] Printer support for PrimValue, StringImm, DataTypeImm (#395)",
    "body": "This PR supports printing out PrimValue, StringImm, DataTypeImm\r\nusing PrettyPrint, which will be used on Python side printing\r\nand sometimes C++ side printing.",
    "author": "MasterJH5574",
    "date": "2023-01-31T23:51:00Z",
    "jobs": []
  },
  {
    "sha": "a35ecb982debc9bec9484a900372b43eb3b87c14",
    "headline": "[BYOC] Refactor and bugfix on `run_codegen` (#382)",
    "body": "* Simplify the codegen behavior. For simplicity, run_codegen pass will now target any function with codegen annotation.\r\n* Update test script to match with the latest TVMScript.\r\n* Minor bug fix for test failure",
    "author": "sunggg",
    "date": "2023-01-31T13:39:17Z",
    "jobs": []
  },
  {
    "sha": "70b9540c88bff37eec108bf880a0340843f32967",
    "headline": "[REFACTOR] Simplify Builtin Ops with PrimValue. (#392)",
    "body": "This PR simplifies CallBuiltin by using PrimValue/StringImm/DataTypeImm\r\nto directly represent the positional argument instead of using customized\r\ntranslation of Attrs.\r\n\r\n- Remove BuiltinFuncAttrs\r\n- Use directly call_packed instead for most cases.\r\n- Introduce call_builtin_with_ctx to cover the remaining usecase of call_builtin\r\n  that requires ctx.\r\n- Update the testcases accordingly.\r\n\r\nThis PR also serves as an example on how can we further simplify other\r\nspecial lowering logics through PrimValue, which can be done in future PRs.",
    "author": "tqchen",
    "date": "2023-01-31T01:26:17Z",
    "jobs": []
  },
  {
    "sha": "a287a962712360d36ba44d51b480ab0a033a77a7",
    "headline": "[FIX][Utils] Add CopyWithNewParams and Check repeated parameters (#389)",
    "body": "This PR adds:\r\n1. A check for any variable used as parameters in different functions of the same IRModule\r\n2. A util to copy function while copying parameters in the new function, so the new function satisfies 1.",
    "author": "Ubospica",
    "date": "2023-01-29T21:53:15Z",
    "jobs": []
  },
  {
    "sha": "29acdf0c10a2adcac184a4b988d91bce858cf32f",
    "headline": "[Op] Completing the unary operators and refactor test (#391)",
    "body": "This PR includes:\r\n- Registering most of the unary operators in [DataAPI](https://data-apis.org/array-api/draft/API_specification/elementwise_functions.html)\r\n- Split unary arith oprators and check operators (e.g. `isnan`)\r\n- Refactor `test_tvmscript_parser`, `test_op_unary` and `test_op_binary` using `tvm.testing.parameters()`.",
    "author": "SiriusNEO",
    "date": "2023-01-29T18:47:25Z",
    "jobs": []
  },
  {
    "sha": "c64cae3cb6695330408dfb8fd99c67521d8426c0",
    "headline": "[ARCH] NestedMsg util functions update (#390)",
    "body": "Added two util functions in `nested_msg.h`:\r\n- `MapToNestedMsgBySInfo`: map Expr to NestedMsg according to StructInfo. If the Expr is not a TupleNode but its StructInfo is TupleStructInfo (for example, Expr is a Var assigned to by a Tuple), it will add TupleGetItem nodes\r\n- `NestedMsgToExpr`: map NestedMsg back to Expr. Tuple nodes will be created.",
    "author": "Ubospica",
    "date": "2023-01-29T16:52:53Z",
    "jobs": []
  },
  {
    "sha": "eb0b0efdf44315bf656f7702901e7b2785de42a0",
    "headline": "[Refactor][AST] `sinfo_args` A3: Well-formed check (#388)",
    "body": "This PR is the last part of the `sinfo_args` switch tracked by #377,\r\nwhich adds the StructInfo check in well-formed check, to ensure that\r\nthe StructInfo in `sinfo_args` does not refer to any undefined\r\nsymbolic variables.",
    "author": "MasterJH5574",
    "date": "2023-01-28T16:01:58Z",
    "jobs": []
  },
  {
    "sha": "7228f487580e24411631dfe9fd8f8244319cea66",
    "headline": "[Refactor][AST] `sinfo_args` A1: Update API of call_tir, call_packed,\u2026",
    "body": "\u2026 etc. (#386)\n\n* [Refactor][AST] `sinfo_args` A1: Update API of call_tir, call_packed, etc\r\n\r\nFollowing #377 and #379, this PR followups to update the API of `call_tir`,\r\n`call_packed`, `call_builtin` and `invoke_closure`.\r\n\r\n* The API of `call_tir` is changed to\r\n  ```python\r\n  def call_tir(\r\n      func: Union[str, Expr],\r\n      args: Expr,\r\n      out_sinfo: Union[TensorStructInfo, TupleStructInfo],\r\n      tir_vars: Optional[Union[ShapeExpr, Tuple[PrimExpr], List[PrimExpr]]] = None,\r\n  ) -> Call:\r\n      ...\r\n  ```\r\n  where we combine the `shape` and `dtype` parameters into `out_sinfo`. In\r\n  the concrete CallNode of `call_tir`, the output shape is no longer passed\r\n  as an CallNode argument and passed in the `sinfo_args` instead.\r\n\r\n* For `call_packed`, `call_builtin` and `invoke_closure`, we change the\r\n  `type_args` parameter to `sinfo_args`. For example, the API of `call_packed`\r\n  is updated to\r\n  ```python\r\n  def call_packed(\r\n      func: str,\r\n      *args: Expr,\r\n      sinfo_args: Union[StructInfo, List[StructInfo]],\r\n      **kwargs: Any,\r\n  ) -> Call:\r\n      ...\r\n  ```\r\n\r\n---\r\n\r\nOne thing specific to note is about our existing dataflow pattern language.\r\nPreviously we have a sugar function for `call_tir`:\r\n```python\r\ndef is_call_tir(\r\n    func_name: str,\r\n    args: Union[List, Tuple, TuplePattern] = None,\r\n    shape: Union[Tuple, List[tvm.ir.PrimExpr], DFPattern] = None,\r\n) -> CallPattern:\r\n    ...\r\n```\r\nSince we changed the API of `call_tir` - the CallNode does not contain the\r\nshape as one argument, - together with the fact that the dataflow pattern\r\nlanguage does not yet support matching StructInfo, we have no approach to\r\nmatch the shape anymore. Therefore, the `shape` parameter is removed from\r\n`is_call_tir`. I left some Todo items there for future `sinfo_args` matching\r\nsupport.\r\n\r\n* Update call_tir API and address comments\r\n\r\nNow the expected type of `out_sinfo` is:\r\n```python\r\nout_sinfo: Union[TensorStructInfo, List[TensorStructInfo]]\r\n```",
    "author": "MasterJH5574",
    "date": "2023-01-28T09:39:33Z",
    "jobs": []
  },
  {
    "sha": "68314b9e3ca194042c5a21eb70691ada5fcc309a",
    "headline": "[Refactor][AST] `sinfo_args` A2: Remove VisitType (#387)",
    "body": "This PR is part of the `sinfo_args` switch, as tracked by #377.\r\n\r\nThis PR removes VisitType from ExprFunctor in Relax, as Type is no\r\nlonger a standalone construct in any Relax AST, with the switch of\r\n`sinfo_args` introduced by #379.",
    "author": "MasterJH5574",
    "date": "2023-01-28T03:51:14Z",
    "jobs": []
  },
  {
    "sha": "942cf28010837d2bcd17ef1b654a44fad73b2499",
    "headline": "[Utils] Introduce Auto Arg Converter for Relax Ops and Functions (#381)",
    "body": "This PR introduce a new decorator to automatically convert the arguments\r\nto the expr according to the Relax Expr, including:\r\n\r\n1. convert `PrimExpr` to `relax.PrimValue`;\r\n2. convert `tvm.String` or `str` to `relax.StringImm`;\r\n3. convert tuple/list of `PrimExpr` to `relax.ShapeExpr`;\r\n4. convert tuple/list of `Expr` to `relax.Tuple`.",
    "author": "Hzfengsy",
    "date": "2023-01-27T17:30:34Z",
    "jobs": []
  },
  {
    "sha": "fc2aa92342eba9262cf5caa15937ab61e79a3761",
    "headline": "[Refacror][AST] `sinfo_args` A0: Introduce `sinfo_args` (#379)",
    "body": "This PR is the kickoff action of our switch towards `sinfo_args` in\r\nCallNode, as discussed in #356 and tracked by #377.\r\n\r\n* CallNode field `type_args` is changed to `sinfo_args`, with type\r\n`Array<StructInfo>`.\r\n\r\n* For intrinsic ops like `call_tir`/`call_packed`, this PR keeps the\r\n`sinfo_args` value as **the plain StructInfo generated from the static\r\ntype**, even if those op calls were provided with richer StructInfo at\r\nthe time of creation. The API changes, creations and structure info\r\ndeductions of these intrinsic ops will be left to the next PR, as the\r\ntracking issue #377. Since that PR, our APIs and structure info\r\ndeductions of these ops will no longer rely on types.",
    "author": "MasterJH5574",
    "date": "2023-01-27T02:24:57Z",
    "jobs": []
  },
  {
    "sha": "55461d1c56e37d593227963db6b86c7368c715b6",
    "headline": "[BYOC] Add DNNL backend (#376)",
    "body": "* Add DNNL backend\r\n\r\n* cpplint\r\n\r\n* skip dnnl test if not enabled\r\n\r\n* fix unused variable warning",
    "author": "masahi",
    "date": "2023-01-26T11:23:18Z",
    "jobs": []
  },
  {
    "sha": "4afff0c03cdf1e23fa0f9db42a5cd526680e4b70",
    "headline": "[TVMScript] Fix py_print direction in IR builder (#378)",
    "body": "Prior to this PR, in `ir.py` of IR builder, the `py_print` directs to the operator `print` instead of Python builtin print.\r\n\r\nThis PR fixes this issue, with a regression test in `tests/python/relax/test_tvmscript_ir_builder.py`.",
    "author": "MasterJH5574",
    "date": "2023-01-26T04:12:56Z",
    "jobs": []
  },
  {
    "sha": "290405fc7001dcfce3fa43c1d076aa662534ae8f",
    "headline": "[Analysis][Tweak] Simplify dataflow block tracking in inner functions\u2026",
    "body": "\u2026 for the well-formed analysis (#374)\n\nThis PR makes a small tweak on the changes in #370. #370 keeps an explicit stack to handle the case of a local function being defined inside a dataflow block. However, this is more complicated than it needs to be: it suffices to keep a single flag for whether the visitor is inside a dataflow block and to save the value of the flag before recursing into a local function definition, similarly to how it handles the var sets.",
    "author": "slyubomirsky",
    "date": "2023-01-26T02:04:58Z",
    "jobs": []
  },
  {
    "sha": "34ff4b06360ebd1574b4b4230ffeb6073792cac0",
    "headline": "[BYOC] Add pass to merge composite functions to offload large subgrap\u2026",
    "body": "\u2026hs (#372)\n\n* Add FuseCompositeFunctions pass\r\n\r\n* clean up and add doc / comments\r\n\r\n* cpplint\r\n\r\n* fix trt build\r\n\r\n* FuseCompositeFunctions -> MergeCompositeFunctions\r\n\r\n* rename\r\n\r\n* add algo explanation\r\n\r\n* Drop requirement on group being always a root in OperatorFusor",
    "author": "masahi",
    "date": "2023-01-25T22:01:31Z",
    "jobs": []
  },
  {
    "sha": "29331a96d5bbc62bdb4deb3db04863dcd1f87fae",
    "headline": "[TVMScript] Fix Return Type for Functions w/o Annotation (#375)",
    "body": "This PR fixes the incorrect function return struct info during declaration info when it's not be annotated.",
    "author": "Hzfengsy",
    "date": "2023-01-25T16:12:31Z",
    "jobs": []
  },
  {
    "sha": "33152b39df21f6c6f00d9e99650a8bc7059efc2d",
    "headline": "[Analysis][Bugfix] Correctly handle dataflow blocks in local function\u2026",
    "body": "\u2026s defined inside a dataflow block (#370)\n\n* Correctly track dataflow block status for nested funcs\r\n\r\n* Similarly update the dataflow var set\r\n\r\n* Use dataflow vars in test case",
    "author": "slyubomirsky",
    "date": "2023-01-23T23:20:17Z",
    "jobs": []
  },
  {
    "sha": "5e4163c2bc6e3090b9d7e82e0d33dd968f793006",
    "headline": "[IR] Initial PrimValue Support (#368)",
    "body": "This PR introduces PrimValue, StringImm and DataTypeImm.\r\n\r\nThese constructs are only used in low-level builtin functions for now.\r\nThey will enable us to effectively represent POD, string and dtype\r\narguments to builtin functions.\r\n\r\nFollowup PRs can be introduced to move some of the BuiltinAttrs\r\nto directly using these values. We can also simplify the handling\r\nof unique and print.\r\n\r\nCo-authored-by: Siyuan Feng <Hzfengsy@sjtu.edu.cn>",
    "author": "tqchen",
    "date": "2023-01-21T23:46:27Z",
    "jobs": []
  },
  {
    "sha": "47f338b0a36bf9f4c2d98aaea2c94cbe294d7c96",
    "headline": "Fix AnnotateTIROpPattern fail on cumsum (#369)",
    "body": "Fallback to kOpaque pattern in presence\r\nof multiple buffer stores in a block.",
    "author": "psrivas2",
    "date": "2023-01-21T13:36:30Z",
    "jobs": []
  },
  {
    "sha": "935cf150fe40a0a71a2be7a847150b1c0e1575e4",
    "headline": "[VM][TVMScript] Shorten VM op names and add TVMScript support (#367)",
    "body": "",
    "author": "Hzfengsy",
    "date": "2023-01-21T13:25:38Z",
    "jobs": []
  },
  {
    "sha": "0073ab7774a219c6f5238f5c0b41bf89ca26fe9e",
    "headline": "[BYOC] Refactor and update `RunCodegen` API (#365)",
    "body": "* Update RunCodegen pass\r\n\r\n* update TensorRT codegen for the new interface\r\n\r\n* typo fix\r\n\r\n* fix unused var warning\r\n\r\n* leave todo comment on dep on RemoveUnusedfunctions\r\n\r\n* introduce src/tranform/utils.h\r\n\r\n* also move GetExtSymbol to transform/utils.h\r\n\r\n* build fix\r\n\r\n* add missing file",
    "author": "masahi",
    "date": "2023-01-21T07:24:21Z",
    "jobs": []
  },
  {
    "sha": "09bba11f258b4819bcceb27de3602d0e1f994e45",
    "headline": "[BYOC] Add pattern-based partitioning pass (#366)",
    "body": "* Add pattern-based partitioning pass\r\n\r\n* add doc\r\n\r\n* add comment\r\n\r\n* changed Python API slightly\r\n\r\n* add more tests\r\n\r\n* remove unused var\r\n\r\n* remove unused import\r\n\r\n* make_conv_pattern -> make_fused_bias_activation_pattern\r\n\r\n* wrap composite_name in Group with std::optional, add doc\r\n\r\n* add optional header\r\n\r\n* Correctly handle tuple output\r\n\r\n* clean test\r\n\r\n* add comment\r\n\r\n* remove unused variable\r\n\r\n* review comments addressed\r\n\r\n* detect cyclic dep\r\n\r\n* clean up test\r\n\r\n* relax.op.nn -> R.nn",
    "author": "masahi",
    "date": "2023-01-21T00:13:13Z",
    "jobs": []
  },
  {
    "sha": "8f4a5a2d427b18f09121316751d1fd7f2e637d81",
    "headline": "[OP] Unary tensor operator `R.exp` (#363)",
    "body": "This PR adds `R.exp`. Besides, it also brings a more comprehensive test for `test_tvmscript_parser_op_arith_cmp`.",
    "author": "SiriusNEO",
    "date": "2023-01-18T13:50:48Z",
    "jobs": []
  },
  {
    "sha": "005cd1e6e5a7f58f60d64ca509dfa64b0f187613",
    "headline": "[Fix][TVMScript] Parse and print `tir_vars` of `call_tir` properly (#\u2026",
    "body": "\u2026361)",
    "author": "MasterJH5574",
    "date": "2023-01-18T00:32:57Z",
    "jobs": []
  },
  {
    "sha": "2d0b90ed98133f8179a9fbdf5a8f0374acf40f13",
    "headline": "[FIX] fix warning for the latest clang (#362)",
    "body": "This PR fixes compilation warnings from the latest clang compiler.",
    "author": "Hzfengsy",
    "date": "2023-01-17T19:09:04Z",
    "jobs": []
  },
  {
    "sha": "ec38fe1c29e875e5720d8ccb8dc2cb0e30a6fc73",
    "headline": "[Op] Change shape-related op attributes to arguments (#360)",
    "body": "",
    "author": "MasterJH5574",
    "date": "2023-01-15T21:13:44Z",
    "jobs": []
  },
  {
    "sha": "fa5476f8ebb35120f1fd5e77dbb02406bdd83c7e",
    "headline": "[Op] Use int64 IntImms as static shape-related attributes (#359)",
    "body": "",
    "author": "MasterJH5574",
    "date": "2023-01-14T23:34:01Z",
    "jobs": []
  },
  {
    "sha": "67d2d08198063050ad4902a3308e96127e746d74",
    "headline": "fix after rebase",
    "body": "",
    "author": "YuchenJin",
    "date": "2023-01-13T21:59:14Z",
    "jobs": []
  },
  {
    "sha": "1f9f9beaf40031f359d33ae19839fdc6a2ee8721",
    "headline": "[Op] Group for conv2d, ceil mode for max_pool2d (#358)",
    "body": "This PR adds the parameter group for conv2d, as well as the option ceil_mode for max_pool2d. They were omitted in the previous round of PR mainly for simplicity, and are introduced now due to their uses in ML frameworks.",
    "author": "MasterJH5574",
    "date": "2023-01-14T00:35:03Z",
    "jobs": []
  },
  {
    "sha": "2b4bf5a36f4e88082a169b414e4cfaa2001eaecb",
    "headline": "[FIX] Fix ShapeExpr/Tuple getitem (#357)",
    "body": "Currently ShapeExpr checks index should be non-negative in `__getitem__`, which is unnecessary and effects the lowering process of several Ops that receives negative index. This PR removes this check.",
    "author": "Ubospica",
    "date": "2023-01-13T18:08:44Z",
    "jobs": []
  },
  {
    "sha": "bf872b9b57c7ed6edec97b53a057f8d47f609f66",
    "headline": "[BlockBuilder] CallTE with PrimExpr support (#353)",
    "body": "",
    "author": "MasterJH5574",
    "date": "2023-01-12T00:30:21Z",
    "jobs": []
  },
  {
    "sha": "4259ad48cbe909109bd40c7ed862368b407d37f0",
    "headline": "[Fix][Op] Fix CallTIR about wrapping args with Tuple (#354)",
    "body": "",
    "author": "MasterJH5574",
    "date": "2023-01-11T21:45:58Z",
    "jobs": []
  },
  {
    "sha": "af50490b5261622bca09b274db1a7c536692c362",
    "headline": "[BlockBuilder] Fix argument conversion for Shape in CallTE (#352)",
    "body": "",
    "author": "MasterJH5574",
    "date": "2023-01-11T21:44:13Z",
    "jobs": []
  },
  {
    "sha": "b1e44dad3119951000d6d6a928502390bb41fbdb",
    "headline": "[Fix][Printer] Fix PrintFinal dispatch for Relax dedicated Expr (#351)",
    "body": "",
    "author": "MasterJH5574",
    "date": "2023-01-11T02:13:39Z",
    "jobs": []
  },
  {
    "sha": "f5da2a687d02d1ef891b9cd97aeb2d5bd495996b",
    "headline": "[UX][TVMScript] Enable relax arithmetic operators (#350)",
    "body": "",
    "author": "Hzfengsy",
    "date": "2023-01-11T01:01:30Z",
    "jobs": []
  },
  {
    "sha": "89706adfc2d7edc54e3ee95acbd23acb6a1b99ee",
    "headline": "[TVMScript][Bugfix] Minor fix for `type_args` and constant printing (\u2026",
    "body": "\u2026#349)\n\n* [TVMScript][Bugfix] Minor fix for `type_args` and constant printing",
    "author": "Hzfengsy",
    "date": "2023-01-10T16:27:13Z",
    "jobs": []
  },
  {
    "sha": "1f3f288dbda27819993ecce4cfe47278f9a02b6a",
    "headline": "[ARCH] NestedMsg util functions (#347)",
    "body": "Add two utility functions of NestedMsg for robust and easy tuple handling.",
    "author": "spectrometerHBH",
    "date": "2023-01-10T15:17:16Z",
    "jobs": []
  },
  {
    "sha": "fcd7e25906ef8d27821de2b7db8cfa15e563a38b",
    "headline": "[Fix] Concurrent modification in RemoveUnusedVars (#348)",
    "body": "\r\nWhen running RemoveUnusedVars (i.e. remove_all_unused), in some cases the map users will raise Concurrent modification error. This commit fixed it by changing the logic to \"iterate the map first and update it later\".\r\n\r\n\r\nCo-authored-by: Chaosfan <siriusneo@sjtu.edu.cn>",
    "author": "MasterJH5574",
    "date": "2023-01-10T03:22:39Z",
    "jobs": []
  },
  {
    "sha": "0effdbd108f3c8799dbb8891b24fce710f2cf6cb",
    "headline": "[Op][O2e] Indexing and datatype operators (#338)",
    "body": "",
    "author": "MasterJH5574",
    "date": "2023-01-09T22:20:05Z",
    "jobs": []
  },
  {
    "sha": "0b1b11d4eeacbc20ac08ff16192db2f9febecb35",
    "headline": "[VM] Supporting \"compiled\" exec mode. (#331)",
    "body": "* [VM] Supporting \"compiled\" exec mode.\r\n\r\nThis PR adds support of \"compiled\" mode to the VM.\r\nThe compiled mode translate the relax function into TIR function\r\nand drive it through the TIR function.\r\n\r\nIt is different from the micro AOT codegen, which generate TIR code\r\nthat targets the micro C runtime environment and useful for resource\r\nlimited settings with smaller set of features. Both leverages the\r\nlow-level TIR build that is also shared with TensorIR.\r\n\r\nThe current implementation targets full TVM (VM) runtime, that\r\ncomes with PackedFunc, object, tuple, closure and all kinds of rich structure\r\nsupport. This also mean that we can leverage the full runtime support\r\nto handle things like allocation, dynamic shape, easy plugins and python\r\ninteraction, which are not available in more limited runtime.\r\n\r\nThe user directly use the same API to load the generated code regardless\r\nof compiled mode or bytecode. And just need to change one line\r\n\r\n```python\r\nex = relax.vm.build(mod, target, exec_mode=\"compiled\")\r\n```\r\n\r\nMost of the codegen features are lifted before the codegen phase,\r\nso the overall implementation would be around 500 loc for each exec mode\r\nand can be further cut down with future introduction of PrimValue.\r\n\r\nThe simplicity is thanks to the TVM runtime archiecture that allows us\r\nto compose things together in objects. The only difference is how\r\nthe PackedFunc of high-level driving is being provided.\r\nIn the case of bytecode it is normal interpretation and in the\r\ncase of compiled mode it is TIR.\r\n\r\nIt is a complete implementation Unit-testcases are added. All codegen\r\nbuild tests are updated to include two exec_modes and have passed locally.\r\nThe only exception that we skipped some special packedfunc handling(printing)\r\nbecause can be further simplified after we introduce PrimValue.\r\n\r\nCo-authored-by: Junru Shao <junrushao1994@gmail.com>\r\n\r\n* Address review comments\r\n\r\nCo-authored-by: Junru Shao <junrushao1994@gmail.com>",
    "author": "tqchen",
    "date": "2023-01-09T19:59:26Z",
    "jobs": []
  },
  {
    "sha": "882cfa8c9189fa377b932a1b966378a2f21a2a55",
    "headline": "[Op][O2d] Manipulation operators (#337)",
    "body": "As tracked by #332, this PR is the O2d milestone of the high-level operator introduction plan.\r\n\r\nThis PR introduces a few manipulation operators:\r\n* broadcast_to\r\n* concat\r\n* expand_dims\r\n* flatten\r\n* permute_dims\r\n* reshape\r\n* split\r\n* squeeze\r\nThese operators are all well-tested.",
    "author": "MasterJH5574",
    "date": "2023-01-09T18:45:14Z",
    "jobs": []
  },
  {
    "sha": "3dcdd9768cdead72f25ac00acceee5a39deaaf69",
    "headline": "[O2h] Neural network and linear algebra operators (#343)",
    "body": "",
    "author": "MasterJH5574",
    "date": "2023-01-09T15:57:19Z",
    "jobs": []
  },
  {
    "sha": "38778ca6d43edbf218e7cd7148fa4d1e58fe48ac",
    "headline": "[O2g] Convolution, pooling and image operators (#341)",
    "body": "",
    "author": "MasterJH5574",
    "date": "2023-01-09T01:21:50Z",
    "jobs": []
  },
  {
    "sha": "779bfd274df6e65648838482cfbde8c23712568f",
    "headline": "[Op][O2f] Set and searching operators (#339)",
    "body": "",
    "author": "MasterJH5574",
    "date": "2023-01-08T21:53:10Z",
    "jobs": []
  },
  {
    "sha": "c7b29363a9a95c8e6f1b67c56b1c9d10fb6f7cf1",
    "headline": "simple fix jupyter error reporting (#345)",
    "body": "",
    "author": "Hzfengsy",
    "date": "2023-01-08T19:38:20Z",
    "jobs": []
  },
  {
    "sha": "b7c7b46497e46796e6c6f1da71409c40e9035a95",
    "headline": "[TVMScript] Symbolic shape computing (#342)",
    "body": "",
    "author": "Hzfengsy",
    "date": "2023-01-08T15:09:22Z",
    "jobs": []
  },
  {
    "sha": "176d374e952eb977596d6a05534ad06f3ee7eb73",
    "headline": "[Op][O2c] Creation operators (#336)",
    "body": "",
    "author": "MasterJH5574",
    "date": "2023-01-07T23:31:00Z",
    "jobs": []
  },
  {
    "sha": "89aadb718aafc2a0775b63d1afaf3dd2e92456b7",
    "headline": "[Op][O2b] Statistical operators (#334)",
    "body": "",
    "author": "MasterJH5574",
    "date": "2023-01-06T21:41:18Z",
    "jobs": []
  },
  {
    "sha": "9ae00865d9d077e666784925d7de25c21ceacaed",
    "headline": "[Op][O1][O2a] Utility, arithmetic and comparison operators (#333)",
    "body": "As tracked by #332, this PR is the kickoff part of high-level operator introduction in Relax.\r\n\r\nThis PR is about the milestone O1 and O2a. Specifically, this PR\r\n* introduces some of common utility functions that the registration and StructInfo inference of each operator will often use.\r\n* introduces unary arithmetic operators: cos, log, negative, sigmoid, sin, sqrt, tanh.\r\n* refactors and introduces binary arithmetic operators: add, divide, floor_divide, multiply, subtract.\r\n* introduces binary comparative operators: equal, greater, greater_equal, less, less_equal, not_equal.\r\n\r\nThese operators are well tested from three perspective:\r\nP1. the op getter can get correct op by name\r\nP2. their StructInfo inference result are as expected under all kinds of cases\r\nP3. Relax TVMScript parser can parse the scripts with the op inside\r\n\r\nFor operators in O2a, most operators share almost the same StructInfo inference logic. Therefore, for tests in P2, in each category, not every op is tested in every case. For each case, it is good to have only part of op in this category tested. This is intended not to make overlarge testing file.",
    "author": "MasterJH5574",
    "date": "2023-01-05T23:31:48Z",
    "jobs": []
  },
  {
    "sha": "957bfaec35254088a261834c4f649e4abc98ab39",
    "headline": "[TVMScript] Ensure consistent struct info between assign lhs and rhs \u2026",
    "body": "\u2026with sinfo annotation (#328)\n\n* [TVMScript] Ensure consistent struct info between assign lhs and rhs with sinfo annotation\n\n* fix\n\n* fix",
    "author": "Hzfengsy",
    "date": "2023-01-05T12:43:28Z",
    "jobs": []
  },
  {
    "sha": "c09046b8aa2315de11364a09879f15e49fbbc4ce",
    "headline": "[REFACTOR] Hide VM Impl, Improve execution logic. (#326)",
    "body": "* [REFACTOR] Hide VM Impl, Improve execution logic.\r\n\r\nThis PR refactors VM by hiding most of the VM implementations\r\nand improve the overall execution logic.\r\n\r\n- Unifies PackedFunc and Closure Table.\r\n- Update Closure mechanism to no longer depend on string.\r\n- Update VMMemoryLower to VMBuiltinLower to incorporate more VM intrinsic lowering,\r\n  move some of the codegen intrinsic to this phase.\r\n- Allow directly pass in function index as VM instruction.\r\n\r\n* Address comment",
    "author": "tqchen",
    "date": "2023-01-04T15:13:08Z",
    "jobs": []
  }
]